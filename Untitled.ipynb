{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词的结果，已经把title权重加大10倍，仅保留了非 d副词m数量词\tq量词\tr代词\tp介词 c连词\tu助词\txc其他虚词\tw标点符号 之外的词性\n",
    "### title中《》里的词作为第一位关键词，如果《》中的名字中间以英语逗号分割，要替换成中文逗号；\n",
    "### tfidf结果中top1作为第二位关键词，判断一下，如果两个词中有两个字及以上重复，则删除，将tfidf结果中top2补上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 加载所有数据，写文件是需要用到id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108295\n",
      "108295\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "alldata = []\n",
    "with open(\"./all_docs.txt\", \"r\", encoding=\"utf-8\") as data:\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        alldata.append(line)\n",
    "        count += 1 \n",
    "print(count)\n",
    "print(len(alldata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    只读取id\n",
    "    只读取title + content\n",
    "    组成一个id：title+\"。\"+content的词典\n",
    "'''\n",
    "train_id_list = []\n",
    "train_title_list = []\n",
    "train_title_content_list = []\n",
    "train_dict = {}  # key = id, value = title+\"。\"+content\n",
    "for line in alldata:\n",
    "    line = line.strip()\n",
    "    if len(line.split(\"\\001\")) == 3:\n",
    "        ids = line.split(\"\\001\")[0]\n",
    "        title = line.split(\"\\001\")[1]\n",
    "        title_content = line.split(\"\\001\")[1] + \"。\" + line.split(\"\\001\")[2]\n",
    "        \n",
    "        train_id_list.append(ids)\n",
    "        train_title_list.append(title)\n",
    "        train_title_content_list.append(title_content)\n",
    "        train_dict[ids] = title_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108295\n",
      "108295\n",
      "108295\n",
      "108295\n"
     ]
    }
   ],
   "source": [
    "print(len(train_id_list))\n",
    "print(len(train_title_list))\n",
    "print(len(train_title_content_list))\n",
    "print(len(train_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_title_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 加载所有已经分过词的文本，title权重已加大10倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "import os \n",
    "for file in os.listdir(\"./getKeyWordsCutData/\"):\n",
    "    if \"txt\" in file:\n",
    "        with open(\"./getKeyWordsCutData/\"+file, \"r\", encoding=\"utf-8\") as data:\n",
    "            for line in data:\n",
    "                line = line.strip()\n",
    "                all_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108295"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_copy = all_data\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 加载停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1533\n"
     ]
    }
   ],
   "source": [
    "stop_words_list = []\n",
    "with open(\"./stop_words.utf8\", \"r\", encoding=\"utf-8\") as stopwords:\n",
    "    for line in stopwords:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            stop_words_list.append(line)\n",
    "print(len(stop_words_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 将分词之后存在于停用词中的词去掉，还有一些乱七八糟的字符，只保留字母和汉字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def useful_char(uchar):\n",
    "    for char in uchar:\n",
    "        if not is_Chinese(char) and not is_alpha(char):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "#judge a character is a Chinese Character\n",
    "def is_Chinese(uchar):\n",
    "    if len(uchar) != 1:\n",
    "        raise 'expected a character, but a string found!'\n",
    " \n",
    "    if uchar >= u'\\u4e00' and uchar <= u'\\u9fa5':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "#Judge a char is a number\n",
    "def is_digit(uchar):\n",
    "    if len(uchar) != 1:\n",
    "        raise 'expected a character, but a string found!'\n",
    " \n",
    "    if uchar >= u'\\u0030' and uchar<=u'\\u0039':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#Judge a char is a alphabet\n",
    "def is_alpha(uchar):\n",
    "    if len(uchar) != 1:\n",
    "        raise 'expected a character, but a string found!'\n",
    " \n",
    "    if (uchar >= u'\\u0041' and uchar<=u'\\u005a') or \\\n",
    "       (uchar >= u'\\u0061' and uchar<=u'\\u007a'):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_useless_words = []\n",
    "for line in all_data:\n",
    "    line_result = []\n",
    "    for word in line.split(\" \"):\n",
    "        if word not in stop_words_list and useful_char(word):\n",
    "            line_result.append(word)\n",
    "    remove_useless_words.append(\" \".join(line_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  自定tfidf，取关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def train_idf(doc_list):\n",
    "    idf_dic = {}\n",
    "    tt_count = len(doc_list) # 获取整个文档集的长度\n",
    "    \n",
    "    # 在整个文档集中，每个单词出现的次数\n",
    "    for doc in doc_list:\n",
    "        for word in set(doc.split(\" \")):\n",
    "            idf_dic[word] = idf_dic.get(word, 0.0) + 1.0\n",
    "    \n",
    "    # 按公式计算idf值，分母加1平滑处理\n",
    "    for k,v in idf_dic.items():\n",
    "        idf_dic[k] = math.log(tt_count / (v+1.0))\n",
    "    \n",
    "    # 没在字典中的字，默认仅在一个文档中出现\n",
    "    default_idf = math.log(tt_count / 1.0)\n",
    "    \n",
    "    return idf_dic, default_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计tf值\n",
    "def train_tf(word_list):\n",
    "    tf_dic = {}\n",
    "    for word in word_list.split(\" \"):\n",
    "        tf_dic[word] = tf_dic.get(word, 0.0) + 1.0\n",
    "    tt_count = len(word_list.split(\" \"))\n",
    "    for k,v in tf_dic.items():\n",
    "        tf_dic[k] = float(v) / tt_count\n",
    "    return tf_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按公式计算tf-idf\n",
    "\n",
    "# idf_dic, default_idf = train_idf(doc_list)\n",
    "\n",
    "def get_tfidf(word_list):\n",
    "    \n",
    "    from functools import reduce\n",
    "    \n",
    "    tf_dic = train_tf(word_list)\n",
    "    \n",
    "    keyword = []\n",
    "    tfidf_dic = {}\n",
    "    \n",
    "    for word in word_list.split(\" \"):\n",
    "        \n",
    "        idf = idf_dic.get(word, default_idf)\n",
    "        tf = tf_dic.get(word, 0)\n",
    "        \n",
    "        tfidf = tf * idf\n",
    "        tfidf_dic[word] = tfidf\n",
    "\n",
    "    for k,v in sorted(tfidf_dic.items(), key=lambda x : x[1], reverse=True)[:10]:\n",
    "        keyword.append(k)\n",
    "        \n",
    "    return reduce(lambda x,y:x+\" \"+y ,keyword)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_keywords = []\n",
    "\n",
    "idf_dic, default_idf = train_idf(remove_useless_words)\n",
    "\n",
    "for line in remove_useless_words:\n",
    "    tfidf_keywords.append(get_tfidf(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_keywords[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 取title中《》里的关键词，如果有\",\"就换成\"，\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "first_keywords = []\n",
    "for line in train_title_list:\n",
    "    first_keywords.append(\" \".join(re.findall(r'\\《(.*?)\\》',line)))\n",
    "\n",
    "for w in first_keywords:\n",
    "    if \",\" in w:\n",
    "        w.replace(\",\", \"，\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8635 你好,之华\n",
      "你好，之华\n",
      "27637 思索,4色\n",
      "思索，4色\n"
     ]
    }
   ],
   "source": [
    "for num, word in enumerate(first_keywords):\n",
    "    if \",\" in word:\n",
    "        print(str(num) + \" \" + word )\n",
    "        first_keywords.remove(first_keywords[num])\n",
    "        first_keywords.insert(num, \"，\".join(word.split(\",\")))\n",
    "        print(first_keywords[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. title中《》里的关键词放第一位，tfidf中top1的词放第二位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_top2_keywords = []\n",
    "\n",
    "for i,j in zip(first_keywords, tfidf_keywords):\n",
    "    line_result = []\n",
    "    for w in i.split(\" \") + j.split(\" \"):\n",
    "        if w and len(w)!=1:\n",
    "            line_result.append(w)\n",
    "   \n",
    "    if len(line_result) >= 2:\n",
    "        final_top2_keywords.append(\",\".join(sorted(set(line_result), key=line_result.index)[:2]))\n",
    "    else:\n",
    "        final_top2_keywords.append(\",\".join(line_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_top2_keywords[:80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 将结果写入文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./example_10TitleWeights_keyWords.csv\", \"w\", encoding=\"utf-8\") as data:\n",
    "    data.write(\"id\" + \",\" + \"label1\" + \",\" + \"label2\" + \"\\n\")\n",
    "    for ids, words in zip(train_id_list, final_top2_keywords):\n",
    "        data.write(str(ids) + \",\" + str(words) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85874   D085874,不对\n",
      "\n",
      "99252   D099252,铲屎\n",
      "\n",
      "102067   D102067,炒菜\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"./example_10TitleWeights_keyWords.csv\", \"r\", encoding=\"utf-8\") as data:\n",
    "    result = data.readlines()\n",
    "    for num, line in enumerate(result):\n",
    "        line = line.strip()\n",
    "        if len(line.split(\",\")) != 3:\n",
    "            print(str(num) + \"   \" + line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'鱼都咬钩了，可千万别因为抬竿不对让它跑了。我们都知道，在钓鱼中，提竿溜鱼是上鱼的最后一步了，之前讲过溜鱼技巧了，今天主要来说说抬竿技巧。说起来抬竿这个步骤是在溜鱼之前的，那么抬竿时要掌握的技巧有哪些呢？下面，一起走进我们的抬竿小课堂学习一下吧。一般来说，在我们钓鱼提竿技巧分为松、直、抖、呛。1、松就是说在我们收线的时候要张弛有度，收线的时候鱼的反抗力弱时可快收。如果反抗力大的时候，我们就要立刻的松线。若是牵强的话，反而会跑掉。2、直就是在我们收线的时候要朝直，直往上抬。切勿左摇右摆的，鱼儿在水中发威时，力量要超过体重若干倍，收线时阻力很大的。这个时候只要往前抬，才能承受压力，如果左右摆动的话，很容易造成断竿的。3、抖就是在鱼上钩后，一定要稳住。先抬起轻轻抖动一下，让鱼钩往深处钩去。钩在鱼嘴里钩牢了，不仅鱼吐不出钩，收线时也可减少滑钩的失误。但一定要轻轻地抖竿，重了会钩破鱼嘴而脱钩。4、呛就是让鱼多呛几口水。收线到一定程度，为防止鱼切线，挣扎逃脱，需将鱼的头部抬出水面，再迅速放下水去。反复几次，再用兜网去兜，就容易收上来。'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_title_content_list[85873]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
