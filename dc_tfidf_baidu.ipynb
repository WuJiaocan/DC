{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用百度API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aip import AipNlp\n",
    "\n",
    "APP_ID = '************'\n",
    "API_KEY = '*********************'\n",
    "SECRET_KEY = '****************************'\n",
    "\n",
    "client = AipNlp(APP_ID, API_KEY, SECRET_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取训练集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108295\n",
      "108295\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "alldata = []\n",
    "with open(\"./all_docs.txt\", \"r\", encoding=\"utf-8\") as data:\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        alldata.append(line)\n",
    "        count += 1 \n",
    "print(count)\n",
    "print(len(alldata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_list = []\n",
    "train_title_content_list = []\n",
    "train_dict = {}  # key = id, value = title+\"。\"+content\n",
    "for line in alldata:\n",
    "    line = line.strip()\n",
    "    if len(line.split(\"\\001\")) == 3:\n",
    "        ids = line.split(\"\\001\")[0]\n",
    "        title_content = line.split(\"\\001\")[1] + \"。\" + line.split(\"\\001\")[2]\n",
    "        \n",
    "        train_id_list.append(ids)\n",
    "        train_title_content_list.append(title_content)\n",
    "        \n",
    "        train_dict[ids] = title_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108295\n",
      "108295\n",
      "108295\n"
     ]
    }
   ],
   "source": [
    "print(len(train_id_list))\n",
    "print(len(train_title_content_list))\n",
    "print(len(train_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    获取测试集的数据id\n",
    "'''\n",
    "test_dict = {} # key = id, value = key words\n",
    "test_id_list = [] # 只获取test data的id\n",
    "test_keywords_list = []\n",
    "with open(\"./train_docs_keywords.txt\", \"r\", encoding=\"utf-8\") as data:\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        test_id_list.append(line.split(\"\\t\")[0])\n",
    "        test_keywords_list.append(line.split(\"\\t\")[1])\n",
    "        test_dict[line.split(\"\\t\")[0]] = line.split(\"\\t\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_id_list))\n",
    "print(len(test_keywords_list))\n",
    "print(len(test_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取测试集文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in test_id_list:\n",
    "    for k, v in train_dict.items():\n",
    "        if i == k:\n",
    "            test_data.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./testData.txt\", \"w\", encoding=\"utf-8\") as test:\n",
    "    for a,b,c in zip(test_id_list, test_data, test_keywords_list):\n",
    "        test.write(str(a) + \" \" + str(b) + \" \" + str(c) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用百度分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除所有半角全角符号，只留字母、数字、中文。\n",
    "def remove_punctuation(line):\n",
    "    rule = re.compile(r'[^a-zA-Z0-9\\u4e00-\\u9fa5]')\n",
    "    line = rule.sub('',line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    result = client.lexerCustom(''.join(e for e in line if e.isalnum()))不能去除所有的特殊符号\n",
    "    result = client.lexerCustom(remove_punctuation(line)) 只保留中文数字字母\n",
    "'''\n",
    "import re\n",
    "test_results = []\n",
    "for num, line in enumerate(test_data):\n",
    "    try:     \n",
    "        result = client.lexerCustom(remove_punctuation(line))  \n",
    "        cut_words = [item.get(\"item\") for item in result.get(\"items\")]\n",
    "        test_results.append(\" \".join(cut_words))\n",
    "    except Exception as e:\n",
    "        print(num + 1)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_results[0].split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def train_idf(doc_list):\n",
    "    idf_dic = {}\n",
    "    tt_count = len(doc_list) # 获取整个文档集的长度\n",
    "    \n",
    "    # 在整个文档集中，每个单词出现的次数\n",
    "    for doc in doc_list:\n",
    "        for word in set(doc.split(\" \")):\n",
    "            idf_dic[word] = idf_dic.get(word, 0.0) + 1.0\n",
    "    \n",
    "    # 按公式计算idf值，分母加1平滑处理\n",
    "    for k,v in idf_dic.items():\n",
    "        idf_dic[k] = math.log(tt_count / (v+1.0))\n",
    "    \n",
    "    # 没在字典中的字，默认仅在一个文档中出现\n",
    "    default_idf = math.log(tt_count / 1.0)\n",
    "    \n",
    "    return idf_dic, default_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计tf值\n",
    "def train_tf(word_list):\n",
    "    tf_dic = {}\n",
    "    for word in word_list.split(\" \"):\n",
    "        tf_dic[word] = tf_dic.get(word, 0.0) + 1.0\n",
    "    tt_count = len(word_list.split(\" \"))\n",
    "    for k,v in tf_dic.items():\n",
    "        tf_dic[k] = float(v) / tt_count\n",
    "    return tf_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按公式计算tf-idf\n",
    "\n",
    "# idf_dic, default_idf = train_idf(doc_list)\n",
    "\n",
    "def get_tfidf(word_list):\n",
    "    \n",
    "    from functools import reduce\n",
    "    \n",
    "    tf_dic = train_tf(word_list)\n",
    "    \n",
    "    keyword = []\n",
    "    tfidf_dic = {}\n",
    "    \n",
    "    for word in word_list.split(\" \"):\n",
    "        \n",
    "        idf = idf_dic.get(word, default_idf)\n",
    "        tf = tf_dic.get(word, 0)\n",
    "        \n",
    "        tfidf = tf * idf\n",
    "        tfidf_dic[word] = tfidf\n",
    "\n",
    "    for k,v in sorted(tfidf_dic.items(), key=lambda x : x[1], reverse=True)[:10]:\n",
    "        keyword.append(k)\n",
    "        \n",
    "    return reduce(lambda x,y:x+\" \"+y ,keyword)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对1000个测试集在百度的分词结果上用tfidf筛选前若干个关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    获取测试集每篇的关键词个数\n",
    "'''\n",
    "true_len_for_each_id = []\n",
    "for i in test_keywords_list:\n",
    "    true_len_for_each_id.append(len(i.split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "for i in test_results:\n",
    "    keywords.append(get_tfidf(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    按实际关键词的长度截取tfidf的结果\n",
    "'''\n",
    "common_part = []\n",
    "for keyword, number in zip(keywords, true_len_for_each_id):\n",
    "    common_part.append(\",\".join(keyword.split(\" \")[:number]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2992"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    test_data中总共有2992个keywords\n",
    "'''\n",
    "from functools import reduce\n",
    "reduce(lambda x,y : x+y, true_len_for_each_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    预测准确的关键词共1145个\n",
    "'''\n",
    "true_keywords_num = 0\n",
    "for true, pred in zip(test_keywords_list, common_part):\n",
    "    true_keywords_num += len([keyword for keyword in true.split(\",\") if keyword in pred.split(\",\")]) \n",
    "print(true_keywords_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二版答案 百度分词，实现tfidf,剔除长度为1的独字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对训练集分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1529\n",
      "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "4228\n",
      "'NoneType' object is not iterable\n",
      "11822\n",
      "'NoneType' object is not iterable\n",
      "14289\n",
      "'NoneType' object is not iterable\n",
      "20399\n",
      "'NoneType' object is not iterable\n",
      "37682\n",
      "'NoneType' object is not iterable\n",
      "38171\n",
      "'NoneType' object is not iterable\n",
      "39866\n",
      "HTTPSConnectionPool(host='aip.baidubce.com', port=443): Max retries exceeded with url: /rpc/2.0/nlp/v1/lexer_custom?access_token=24.ecfd82c60fa16ebdadb9f2b88dd8e85b.2592000.1539316035.282335-11513666 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0a4d30a588>: Failed to establish a new connection: [Errno -2] Name or service not known',))\n",
      "39871\n",
      "HTTPSConnectionPool(host='aip.baidubce.com', port=443): Max retries exceeded with url: /rpc/2.0/nlp/v1/lexer_custom?access_token=24.ecfd82c60fa16ebdadb9f2b88dd8e85b.2592000.1539316035.282335-11513666 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0a4d30a198>: Failed to establish a new connection: [Errno -2] Name or service not known',))\n",
      "44542\n",
      "'NoneType' object is not iterable\n",
      "49203\n",
      "'NoneType' object is not iterable\n",
      "52608\n",
      "'NoneType' object is not iterable\n",
      "53705\n",
      "'NoneType' object is not iterable\n",
      "55001\n",
      "'NoneType' object is not iterable\n",
      "56124\n",
      "'NoneType' object is not iterable\n",
      "56592\n",
      "'NoneType' object is not iterable\n",
      "61981\n",
      "'NoneType' object is not iterable\n",
      "62153\n",
      "'NoneType' object is not iterable\n",
      "64085\n",
      "'NoneType' object is not iterable\n",
      "64220\n",
      "'NoneType' object is not iterable\n",
      "64450\n",
      "'NoneType' object is not iterable\n",
      "64484\n",
      "'NoneType' object is not iterable\n",
      "64797\n",
      "'NoneType' object is not iterable\n",
      "67753\n",
      "'NoneType' object is not iterable\n",
      "69597\n",
      "'NoneType' object is not iterable\n",
      "69660\n",
      "'NoneType' object is not iterable\n",
      "70056\n",
      "'NoneType' object is not iterable\n",
      "71610\n",
      "'NoneType' object is not iterable\n",
      "71976\n",
      "'NoneType' object is not iterable\n",
      "72057\n",
      "'NoneType' object is not iterable\n",
      "72168\n",
      "'NoneType' object is not iterable\n",
      "72254\n",
      "'NoneType' object is not iterable\n",
      "72260\n",
      "'NoneType' object is not iterable\n",
      "72261\n",
      "'NoneType' object is not iterable\n",
      "72564\n",
      "'NoneType' object is not iterable\n",
      "75476\n",
      "HTTPSConnectionPool(host='aip.baidubce.com', port=443): Max retries exceeded with url: /rpc/2.0/nlp/v1/lexer_custom?access_token=24.ecfd82c60fa16ebdadb9f2b88dd8e85b.2592000.1539316035.282335-11513666 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0a4d0186d8>: Failed to establish a new connection: [Errno -2] Name or service not known',))\n",
      "78411\n",
      "'NoneType' object is not iterable\n",
      "83406\n",
      "'NoneType' object is not iterable\n",
      "88756\n",
      "'NoneType' object is not iterable\n",
      "89722\n",
      "'NoneType' object is not iterable\n",
      "90104\n",
      "'NoneType' object is not iterable\n",
      "90282\n",
      "'NoneType' object is not iterable\n",
      "90611\n",
      "'NoneType' object is not iterable\n",
      "90913\n",
      "'NoneType' object is not iterable\n",
      "90954\n",
      "'NoneType' object is not iterable\n",
      "92233\n",
      "'NoneType' object is not iterable\n",
      "92333\n",
      "'NoneType' object is not iterable\n",
      "92635\n",
      "'NoneType' object is not iterable\n",
      "92645\n",
      "'NoneType' object is not iterable\n",
      "92730\n",
      "'NoneType' object is not iterable\n",
      "93021\n",
      "'NoneType' object is not iterable\n",
      "93321\n",
      "'NoneType' object is not iterable\n",
      "93489\n",
      "'NoneType' object is not iterable\n",
      "93496\n",
      "'NoneType' object is not iterable\n",
      "94173\n",
      "'NoneType' object is not iterable\n",
      "95088\n",
      "'NoneType' object is not iterable\n",
      "96831\n",
      "'NoneType' object is not iterable\n",
      "96964\n",
      "'NoneType' object is not iterable\n",
      "98085\n",
      "'NoneType' object is not iterable\n",
      "99599\n",
      "'NoneType' object is not iterable\n",
      "103486\n",
      "'NoneType' object is not iterable\n",
      "107196\n",
      "'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    QPS会有限制\n",
    "'''\n",
    "import re\n",
    "train_results = []\n",
    "for num, line in enumerate(train_title_content_list):\n",
    "    try:     \n",
    "        result = client.lexerCustom(remove_punctuation(line))  \n",
    "        cut_words = [item.get(\"item\") for item in result.get(\"items\")]\n",
    "        train_results.append(\" \".join(cut_words))\n",
    "    except Exception as e:\n",
    "        print(num + 1)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "108295 - 108233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_results = train_results # origial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108233"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(copy_train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_train_results_1 = train_results # 更正1个了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108234"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(copy_train_results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108236\n"
     ]
    }
   ],
   "source": [
    "copy_train_results_3 = train_results # 更正3个了\n",
    "print(len(copy_train_results_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量处理因为文本过大造成的没有分词的文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108237"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "number.insert(0, 20398)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "[20398, 37681, 38170, 39865, 39870, 44541, 49202, 52607, 53704, 55000, 56123, 56591, 61980, 62152, 64084, 64219, 64449, 64483, 64796, 67752, 69596, 69659, 70055, 71609, 71975, 72056, 72167, 72253, 72259, 72260, 72563, 75475, 78410, 83405, 88755, 89721, 90103, 90281, 90610, 90912, 90953, 92232, 92332, 92634, 92644, 92729, 93020, 93320, 93488, 93495, 94172, 95087, 96830, 96963, 98084, 99598, 103485, 107195]\n"
     ]
    }
   ],
   "source": [
    "print(len(number))\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对第20398篇文章处理中...\n",
      "文章包含正常符号数 449\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第37681篇文章处理中...\n",
      "文章包含正常符号数 14420\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第38170篇文章处理中...\n",
      "文章包含正常符号数 12171\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第39865篇文章处理中...\n",
      "文章包含正常符号数 1917\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第39870篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 324\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第44541篇文章处理中...\n",
      "文章包含正常符号数 23153\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第49202篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 17063\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第52607篇文章处理中...\n",
      "文章包含正常符号数 11402\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第53704篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 11768\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第55000篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 10431\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第56123篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 11142\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第56591篇文章处理中...\n",
      "文章包含正常符号数 12710\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第61980篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 11416\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第62152篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 13561\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第64084篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 122\n",
      "已插入对应位置\n",
      "对第64219篇文章处理中...\n",
      "文章包含正常符号数 13749\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第64449篇文章处理中...\n",
      "文章包含正常符号数 19867\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第64483篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 13036\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第64796篇文章处理中...\n",
      "文章包含正常符号数 11387\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第67752篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 11679\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第69596篇文章处理中...\n",
      "文章包含正常符号数 13828\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第69659篇文章处理中...\n",
      "文章包含正常符号数 11929\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第70055篇文章处理中...\n",
      "文章包含正常符号数 12865\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第71609篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 18524\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第71975篇文章处理中...\n",
      "文章包含正常符号数 12025\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第72056篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 12275\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第72167篇文章处理中...\n",
      "文章包含正常符号数 13046\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第72253篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 25\n",
      "已插入对应位置\n",
      "对第72259篇文章处理中...\n",
      "文章包含正常符号数 16985\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第72260篇文章处理中...\n",
      "文章包含正常符号数 16541\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第72563篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 497\n",
      "已插入对应位置\n",
      "对第75475篇文章处理中...\n",
      "文章包含正常符号数 494\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第78410篇文章处理中...\n",
      "文章包含正常符号数 11009\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第83405篇文章处理中...\n",
      "文章包含正常符号数 12074\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第88755篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 11991\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第89721篇文章处理中...\n",
      "文章包含正常符号数 12901\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第90103篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 11413\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第90281篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 12925\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第90610篇文章处理中...\n",
      "文章包含正常符号数 18709\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第90912篇文章处理中...\n",
      "文章包含正常符号数 13209\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第90953篇文章处理中...\n",
      "文章包含正常符号数 11727\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第92232篇文章处理中...\n",
      "文章包含正常符号数 10886\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第92332篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 12888\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第92634篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 22851\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第92644篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 13065\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第92729篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 10749\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第93020篇文章处理中...\n",
      "文章包含正常符号数 10532\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第93320篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 12382\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第93488篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 14492\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第93495篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 11011\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第94172篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 13722\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第95087篇文章处理中...\n",
      "文章包含正常符号数 11298\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第96830篇文章处理中...\n",
      "文章包含正常符号数 14325\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第96963篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 15212\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第98084篇文章处理中...\n",
      "'NoneType' object is not iterable\n",
      "文章包含正常符号数 15310\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第99598篇文章处理中...\n",
      "文章包含正常符号数 10372\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第103485篇文章处理中...\n",
      "文章包含正常符号数 11809\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n",
      "对第107195篇文章处理中...\n",
      "文章包含正常符号数 10715\n",
      "分词前后文本的长度一致\n",
      "已插入对应位置\n"
     ]
    }
   ],
   "source": [
    "for i in number:\n",
    "    # 对每篇文章，在句号分词之后，每句话分词\n",
    "    print(\"对第%d篇文章处理中...\"%i)\n",
    "    add_cut_words = []\n",
    "    for line in train_title_content_list[int(i)].split(\"。\"):\n",
    "        sent = remove_punctuation(line)\n",
    "        add_result = client.lexerCustom(sent) \n",
    "        try:\n",
    "            add_cut_words.extend([item.get(\"item\") for item in add_result.get(\"items\")])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    # 验证是否分词正确\n",
    "    # 获取分词之后的所有字数\n",
    "    total_len = 0\n",
    "    for j in add_cut_words:\n",
    "        total_len += len(j)\n",
    "    print(\"文章包含正常符号数\", total_len)\n",
    "    # 获取分词之前去掉所有符号之后的长度\n",
    "\n",
    "    if len(remove_punctuation(train_title_content_list[int(i)])) == total_len:\n",
    "        print(\"分词前后文本的长度一致\")\n",
    "    \n",
    "    # 将分词的格式转换\n",
    "    add_cut_words = \" \".join(add_cut_words)\n",
    "    \n",
    "    # 插入到应该插入的位置\n",
    "    train_results.insert(int(i) ,add_cut_words)\n",
    "    print(\"已插入对应位置\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计每篇文章的tfidf，找出关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108295"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dic, default_idf = train_idf(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "for i in train_results:\n",
    "    keywords.append(get_tfidf(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108295"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108295"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'杨幂 4月29日 大幂幂 瘦 主编 并发文 托腮 张宇 漂亮 夸奖'"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    从10个关键词中提取两个关键词\n",
    "'''\n",
    "sents = []\n",
    "for line in keywords:\n",
    "    sent = []\n",
    "    for word in line.split(\" \"):\n",
    "        if len(word) != 1:\n",
    "            sent.append(word)\n",
    "            if len(sent) == 2:\n",
    "                break\n",
    "            sents.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['放入', '排骨']"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'花椒,姜蒜'"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(sents[-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_results = [\",\".join(sent) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'陈若仪,睫毛'"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108295"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keywords_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./example2.csv\", \"w\", encoding=\"utf-8\") as data:\n",
    "    data.write(\"id\" + \",\" + \"label1\" + \",\" + \"label2\" + \"\\n\")\n",
    "    for i,j in zip(train_id_list, keywords_results):\n",
    "        data.write(i + \",\" + j + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三版答案，增加title的权重，在现有分词结果的基础上，将title再次分词，重复5遍，加入到原有的分词结果中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'陈若仪 睫毛 面膜 林志颖 安利 洁面 日常 她 呐 隔离日'"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108295\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    只读取训练集的title\n",
    "'''\n",
    "train_title_list = []\n",
    "for line in alldata:\n",
    "    line = line.strip()\n",
    "    if len(line.split(\"\\001\")) == 3:\n",
    "        title = line.split(\"\\001\")[1]\n",
    "        train_title_list.append(title)\n",
    "print(len(train_title_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700\n",
      "'NoneType' object is not iterable\n",
      "******************\n",
      "2717\n",
      "'NoneType' object is not iterable\n",
      "******************\n",
      "2726\n",
      "'NoneType' object is not iterable\n",
      "******************\n",
      "2727\n",
      "'NoneType' object is not iterable\n",
      "******************\n",
      "2736\n",
      "'NoneType' object is not iterable\n",
      "******************\n",
      "2753\n",
      "'NoneType' object is not iterable\n",
      "******************\n",
      "2758\n",
      "'NoneType' object is not iterable\n",
      "******************\n",
      "2763\n",
      "'NoneType' object is not iterable\n",
      "******************\n",
      "2764\n",
      "'NoneType' object is not iterable\n",
      "******************\n",
      "2769\n",
      "'NoneType' object is not iterable\n",
      "******************\n",
      "2774\n",
      "'NoneType' object is not iterable\n",
      "******************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[0;34m(self, ssl, result)\u001b[0m\n\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWantReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-587-77c9a005e6bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_title_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gb2312'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gb2312'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gbk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gbk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0madd_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexerCustom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0madd_titles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"item\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madd_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"items\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/aip/nlp.py\u001b[0m in \u001b[0;36mlexerCustom\u001b[0;34m(self, text, options)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__lexerCustomUrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdepParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/aip/base.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, url, data, headers)\u001b[0m\n\u001b[1;32m     96\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__connectTimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__socketTimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                             ), proxies=self._proxies\n\u001b[0m\u001b[1;32m     99\u001b[0m                         )\n\u001b[1;32m    100\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proccessResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \"\"\"\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The read operation timed out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mwait_for_read\u001b[0;34m(socks, timeout)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mor\u001b[0m \u001b[0moptionally\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0msocket\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     sockets that can be read from immediately. \"\"\"\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wait_for_io_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVENT_READ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36m_wait_for_io_events\u001b[0;34m(socks, events, timeout)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return [key[0].fileobj for key in\n\u001b[0;32m---> 26\u001b[0;31m                 selector.select(timeout) if key[1] & events]\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/util/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m             fd_events = _syscall_wrapper(self._epoll.poll, True,\n\u001b[1;32m    437\u001b[0m                                          \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                                          maxevents=max_events)\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_mask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfd_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/urllib3/util/selectors.py\u001b[0m in \u001b[0;36m_syscall_wrapper\u001b[0;34m(func, _, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         and recalculate their timeouts. \"\"\"\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0merrcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "    对title进行分词\n",
    "'''\n",
    "import time\n",
    "add_titles = []\n",
    "count = 0\n",
    "for num, title in enumerate(train_title_list):\n",
    "    title = title.encode('gb2312', 'ignore').decode('gb2312').encode('gbk', 'ignore').decode('gbk')\n",
    "    add_result = client.lexerCustom(title) \n",
    "    try:\n",
    "        add_titles.append([item.get(\"item\") for item in add_result.get(\"items\")])\n",
    "        count += 1\n",
    "    except Exception as e:\n",
    "        print(num)\n",
    "        print(e)  \n",
    "        print(\"******************\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    分词的结果重复五倍\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
