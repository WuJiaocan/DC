{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108295\n",
      "108295\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "alldata = []\n",
    "with open(\"./all_docs.txt\", \"r\", encoding=\"utf-8\") as data:\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        alldata.append(line)\n",
    "        count += 1 \n",
    "print(count)\n",
    "print(len(alldata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取训练集的id和对应的title_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.analyse as aly\n",
    "train_id_list = []\n",
    "train_title_content_list = []\n",
    "train_dict = {}  # key = id, value = title+\"。\"+content\n",
    "for line in alldata:\n",
    "    line = line.strip()\n",
    "    if len(line.split(\"\\001\")) == 3:\n",
    "        ids = line.split(\"\\001\")[0]\n",
    "        title_content = line.split(\"\\001\")[1] + \"。\" + line.split(\"\\001\")[2]\n",
    "        \n",
    "        train_id_list.append(ids)\n",
    "        train_title_content_list.append(title_content)\n",
    "        \n",
    "        train_dict[ids] = title_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108295\n",
      "108295\n",
      "108295\n"
     ]
    }
   ],
   "source": [
    "print(len(train_id_list))\n",
    "print(len(train_title_content_list))\n",
    "print(len(train_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取测试集的id和对应的key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    获取测试集的数据id\n",
    "'''\n",
    "test_dict = {} # key = id, value = key words\n",
    "test_id_list = [] # 只获取test data的id\n",
    "test_keywords_list = []\n",
    "with open(\"./train_docs_keywords.txt\", \"r\", encoding=\"utf-8\") as data:\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        test_id_list.append(line.split(\"\\t\")[0])\n",
    "        test_keywords_list.append(line.split(\"\\t\")[1])\n",
    "        test_dict[line.split(\"\\t\")[0]] = line.split(\"\\t\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_id_list))\n",
    "print(len(test_keywords_list))\n",
    "print(len(test_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D012650'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对测试集的文本数据做关键词提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in test_id_list:\n",
    "    for k, v in train_dict.items():\n",
    "        if i == k:\n",
    "            test_data.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.load_userdict(\"./user_dict.txt\")\n",
    "# jieba.add_word(\"三生三世\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tdidf提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words_tfidf = []\n",
    "for line in test_data:\n",
    "    key_words_tfidf.append(aly.extract_tags(line)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['三生三世', '东华', '热巴', '桃花', '出演', '十里', '一部', '枕上', '剧情', '迪丽']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_words_tfidf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### textrank提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words_textrank = []\n",
    "for line in test_data:\n",
    "    key_words_textrank.append(aly.textrank(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['是', '三生三世', '书', '剧情', '作品', '热巴', '桃花', '来', '知道', '制作']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_words_textrank[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 每篇测试集只提取tfidf和textrank结果重合部分的前2个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_part = []\n",
    "common = zip(key_words_tfidf, key_words_textrank)\n",
    "for tfidf, textrank in common:\n",
    "#     print(tfidf, textrank)\n",
    "#     print(\"**************\")\n",
    "    con = [i for i in tfidf if i in textrank]\n",
    "    common_part.append(','.join(con[:2]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'三生三世,热巴'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_part[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对比测试集的结果 vs tdidf/textrank取共同集合前2个获得的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247.5\n"
     ]
    }
   ],
   "source": [
    "# true keywords: test_keywords_list\n",
    "# pred keywprds: common_part\n",
    "score = 0\n",
    "for true, pred in zip(test_keywords_list, common_part):\n",
    "    score += len([keyword for keyword in true.split(\",\") if keyword in pred.split(\",\")]) * 0.5\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按照测试集每篇真实的关键词的个数，提取tfidf和textrank重合部分的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    获取测试集中每篇文章实际的keywords的长度\n",
    "'''\n",
    "true_len_for_each_id = []\n",
    "for i in test_keywords_list:\n",
    "    true_len_for_each_id.append(len(i.split(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_len_for_each_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    获取tfidf和textrank重叠的结果\n",
    "'''\n",
    "common_part_2 = []\n",
    "common = zip(key_words_tfidf, key_words_textrank)\n",
    "for tfidf, textrank in common:\n",
    "#     print(tfidf, textrank)\n",
    "#     print(\"**************\")\n",
    "    con = [i for i in tfidf if i in textrank]\n",
    "    common_part_2.append(','.join(con))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    按实际关键词的长度截取tfidf和textrank重叠的结果\n",
    "'''\n",
    "common_part_22 = []\n",
    "for keywords, number in zip(common_part_2, true_len_for_each_id):\n",
    "#     print(keywords.split(\",\")[:number])\n",
    "    common_part_22.append(\",\".join(keywords.split(\",\")[:number]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    预测准确的关键词共620个\n",
    "'''\n",
    "true_keywords_num = 0\n",
    "for true, pred in zip(test_keywords_list, common_part_22):\n",
    "    true_keywords_num += len([keyword for keyword in true.split(\",\") if keyword in pred.split(\",\")]) \n",
    "print(true_keywords_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2992"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    test_data中总共有2992个keywords\n",
    "'''\n",
    "from functools import reduce\n",
    "reduce(lambda x,y : x+y, true_len_for_each_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一版答案，先按照tfidf和textrank结果，取重叠部分的前2个，作为最终的all docs的关键词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108295\n",
      "108295\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "alldata = []\n",
    "with open(\"./all_docs.txt\", \"r\", encoding=\"utf-8\") as data:\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        alldata.append(line)\n",
    "        count += 1 \n",
    "print(count)\n",
    "print(len(alldata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取训练集的id和相应的title_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.analyse as aly\n",
    "train_id_list = []\n",
    "train_title_content_list = []\n",
    "train_dict = {}  # key = id, value = title+\"。\"+content\n",
    "for line in alldata:\n",
    "    line = line.strip()\n",
    "    if len(line.split(\"\\001\")) == 3:\n",
    "        ids = line.split(\"\\001\")[0]\n",
    "        title_content = line.split(\"\\001\")[1] + \"。\" + line.split(\"\\001\")[2]\n",
    "        \n",
    "        train_id_list.append(ids)\n",
    "        train_title_content_list.append(title_content)\n",
    "        \n",
    "        train_dict[ids] = title_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108295\n",
      "108295\n",
      "108295\n"
     ]
    }
   ],
   "source": [
    "print(len(id_list))\n",
    "print(len(title_content_list))\n",
    "print(len(train_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf，textrank分别提取关键词，并取前2个重叠的关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108295\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse as aly\n",
    "\n",
    "# tfidf提取关键词\n",
    "tfidf = []\n",
    "for line in title_content_list:\n",
    "    tfidf.append(aly.extract_tags(line))\n",
    "print(len(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19146\n",
      "float division by zero\n",
      "21348\n",
      "float division by zero\n",
      "87502\n",
      "float division by zero\n",
      "108292\n"
     ]
    }
   ],
   "source": [
    "# textrank提取关键词\n",
    "textrank = []\n",
    "for num, line in enumerate(title_content_list):\n",
    "    try:\n",
    "        textrank.append(aly.textrank(line))\n",
    "    except Exception as e:\n",
    "        print(num+1)\n",
    "        print(e)\n",
    "print(len(textrank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank.insert(19145,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank.insert(21347,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank.insert(87501,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108295"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(textrank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textrank分词结果不太好，弃用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载自定义词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 直接取tfidf的结果前两个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_select_2 = []\n",
    "for keywords in tfidf:\n",
    "    tfidf_select_2.append(keywords[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108295"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_select_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "tfidf_select_22 = []\n",
    "for line in tfidf_select_2:\n",
    "    tfidf_select_22.append(reduce(lambda x, y: x + \",\" + y, line)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'陈若仪,睫毛'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_select_22[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 写成提交的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108295"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./example.csv\", \"w\", encoding=\"utf-8\") as result:\n",
    "    result.write(\"id\" + \",\" + \"lable1\" + \",\" + \"lable2\" + \"\\n\")\n",
    "    for ids, keywords in zip(train_id_list, tfidf_select_22):\n",
    "        result.write(ids + \",\" + keywords.strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
